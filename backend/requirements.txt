# VERCEL PRODUCTION - FULL RAG WITH PINECONE
# FastAPI and ASGI server
fastapi==0.115.5
uvicorn==0.32.1
mangum>=0.17.0

# Database
sqlalchemy==2.0.36
psycopg2-binary==2.9.9  # PostgreSQL driver for Neon

# JIRA Integration
jira==3.8.0

# Slack Integration
slack-sdk==3.33.4

# AI & RAG (Minimal - Direct SDK usage)
google-generativeai>=0.8.0
pinecone-client>=5.0.0

# Configuration
python-dotenv==1.0.1
pydantic==2.10.2
pydantic-settings==2.6.1

# HTTP Client
httpx==0.27.2
requests==2.32.3

# Monitoring
loguru==0.7.3

# Multipart support
python-multipart>=0.0.9

# Document parsing (lightweight)
pypdf>=4.0.0
python-docx>=1.1.0

# OPTIMIZED FOR VERCEL (Minimal bundle):
# ✅ Pinecone SDK directly (no llama-index = huge size savings!)
# ✅ Google Generative AI for embeddings
# ❌ Removed: llama-index (and its heavy deps: numpy, pandas, nltk)
# ❌ Removed: presidio, celery, redis (optional features)
